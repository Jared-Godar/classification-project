{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e2939e",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8e127",
   "metadata": {},
   "source": [
    "by Jared Godar 2021-11-29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4776813",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9b9a5",
   "metadata": {},
   "source": [
    "## Project Goal\n",
    "\n",
    "This project aims to use historical customer data to build a classification model to predict what customers are likely to churn to identify drivers of churn to devise better customer retention strategies.\n",
    "\n",
    "## Project Description\n",
    "\n",
    "Acquiring new customers is expensive. Between marketing costs and initial offers and promotions, a significant investment is made in bringing a customer to Telco, Inc. We are losing too many customers to our competitors and having to find new customers to replace them. Here we will analyze the attributes of customers who leave and stay, develop a model to predict churn based on those attributes, make recommendations to increase customer retention, and provide a list of current customers and their predicted likelihood to churn.\n",
    "\n",
    "## Initial Questions\n",
    "\n",
    "Are there any demographic categories (age, sex, etc.) more or less likely to churn?\n",
    "\n",
    "Does the type of service or services the customer subscribes to influence churn?\n",
    "\n",
    "How do customer's charges influence churn?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d508f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4fe207",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605018a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdb05a",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Here we import the various functions, modules, and libraries necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfb4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# import splitting and imputing functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# turn off pink boxes for demo\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import our own acquire module\n",
    "import telcoacquire\n",
    "\n",
    "# Remove limits on viewing dataframes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6947ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4804b0",
   "metadata": {},
   "source": [
    "## Wrangle Telco Dat\n",
    "\n",
    "To acquire the titanic data, I used the `telco_churn` datbase on the Codeup server, selecting all columns from the `customers` atabnle and joining the `contract_type_id`, `internet_service_types`, and `payment_type_id` tables with the following query:\n",
    "\n",
    "    select * from customers\n",
    "                join contract_types using (contract_type_id)\n",
    "                join internet_service_types using (internet_service_type_id)\n",
    "                join payment_types using (payment_type_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bb26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire data from the sql database telco_churn\n",
    "\n",
    "telco_df = telcoacquire.new_telco_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2237d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54327636",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "To clean the data, I did the following:\n",
    "\n",
    "1. Dropped Columns\n",
    "    - *Duplicates:* Since `payment_type_id` duplicates `payment_type`, `internet_service_type_id` duplicates `internet_service_type`, and `contract_type_id` duplicates `contract_type`, we only need one column of each pair. Drop the `_id` columns\n",
    "    - *Unhelpful:* `customer_id` should provide no predictive value for our model and can be dropped as well.\n",
    "2. Dropped Rows\n",
    "    - There were 11 new customers with null values for total charges\n",
    "    - Since these customers have not had an opportunity to churn, they offer no predictive value and were fropped from the dataset\n",
    "3. Changed the `total_charges` column data type from `object` to `float`.\n",
    "4. Created Dummy Variables for object data types\n",
    "    - Columns with two options were assigned a new encoded column with the values `0` or `1` (`gender`, `partner`, `dependents`, `phonse_service`, `paperless_billing`, `churn`)\n",
    "    - Columns with more than two options were one-hot encoded (`multiple_lines`, `online_security`, `online_backup`, `device_protection`, `tech_support`, `streaming_tv`, `streaming_movies`, `contract_type`, `internet_service_type`, `payment_type`)\n",
    "5. Encoding created some redundant columns `no_phone` `no_internet`. Since this information was captured elsewhere, these columns were also dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565a1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telco_prepare\n",
    "\n",
    "telco_df=telco_prepare.prep_telco(telco_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1afcba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e993641",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "\n",
    "Data will be split into a training, validation, and test data set:\n",
    "    - *Train* Perform exploratory analysis and construct models\n",
    "    - *Validate* verify models are not overfit to training data\n",
    "    - *Test* used only once with the best model to approximate how the model will perform on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240a3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco_train, telco_validate, telco_test=telco_prepare.split_telco(telco_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b4fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
